<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>黑马程序员-Kafka | WeiBlog</title><meta name="author" content="Wei Shao"><meta name="copyright" content="Wei Shao"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Kafka入门简介消息队列简介什么是消息队列消息队列，英文名：Message Queue，经常缩写为MQ。从字面上来理解，消息队列是一种用来存储消息的队列。来看一下下面的代码： 123456789&#x2F;&#x2F; 1. 创建一个保存字符串的队列Queue&lt;String&gt; stringQueue &#x3D; new LinkedList&lt;String&gt;();&#x2F;&#x2F; 2. 往消息队列中放入消息str">
<meta property="og:type" content="article">
<meta property="og:title" content="黑马程序员-Kafka">
<meta property="og:url" content="https://weishao-996.github.io/2023/02/20/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/index.html">
<meta property="og:site_name" content="WeiBlog">
<meta property="og:description" content="Kafka入门简介消息队列简介什么是消息队列消息队列，英文名：Message Queue，经常缩写为MQ。从字面上来理解，消息队列是一种用来存储消息的队列。来看一下下面的代码： 123456789&#x2F;&#x2F; 1. 创建一个保存字符串的队列Queue&lt;String&gt; stringQueue &#x3D; new LinkedList&lt;String&gt;();&#x2F;&#x2F; 2. 往消息队列中放入消息str">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://weishao-996.github.io/img/bg/WechatIMG48.png">
<meta property="article:published_time" content="2023-02-20T12:40:50.000Z">
<meta property="article:modified_time" content="2023-03-04T14:31:36.533Z">
<meta property="article:author" content="Wei Shao">
<meta property="article:tag" content="Kafka">
<meta property="article:tag" content="黑马程序员">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://weishao-996.github.io/img/bg/WechatIMG48.png"><link rel="shortcut icon" href="/img/bg/%E6%89%8B%E7%BB%98%E7%81%AB%E7%AE%AD.png"><link rel="canonical" href="https://weishao-996.github.io/2023/02/20/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '黑马程序员-Kafka',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-03-04 22:31:36'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = url => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      link.onload = () => resolve()
      link.onerror = () => reject()
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/bg/WechatIMG48.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">24</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">16</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/bg/iTab-7p3we9.jpeg')"><nav id="nav"><span id="blog-info"><a href="/" title="WeiBlog"><span class="site-name">WeiBlog</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">黑马程序员-Kafka</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-02-20T12:40:50.000Z" title="发表于 2023-02-20 20:40:50">2023-02-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-03-04T14:31:36.533Z" title="更新于 2023-03-04 22:31:36">2023-03-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/">消息中间件</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/Kafka/">Kafka</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="黑马程序员-Kafka"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Kafka入门"><a href="#Kafka入门" class="headerlink" title="Kafka入门"></a>Kafka入门</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><h3 id="消息队列简介"><a href="#消息队列简介" class="headerlink" title="消息队列简介"></a>消息队列简介</h3><h4 id="什么是消息队列"><a href="#什么是消息队列" class="headerlink" title="什么是消息队列"></a>什么是消息队列</h4><p>消息队列，英文名：Message Queue，经常缩写为MQ。从字面上来理解，消息队列是一种用来存储消息的队列。来看一下下面的代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1. 创建一个保存字符串的队列</span></span><br><span class="line">Queue&lt;String&gt; stringQueue = <span class="keyword">new</span> <span class="title class_">LinkedList</span>&lt;String&gt;();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. 往消息队列中放入消息</span></span><br><span class="line">stringQueue.offer(<span class="string">&quot;hello&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3. 从消息队列中取出消息并打印</span></span><br><span class="line">System.out.println(stringQueue.poll());</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>上述代码，创建了一个队列，先往队列中添加了一个消息，然后又从队列中取出了一个消息。这说明了队列是可以用来存取消息的。我们可以简单理解消息队列就是<strong>将需要传输的数据存放在队列中</strong>。</p>
<h4 id="消息队列中间件"><a href="#消息队列中间件" class="headerlink" title="消息队列中间件"></a>消息队列中间件</h4><p>消息队列中间件就是用来存储消息的软件（组件）。举个例子来理解，为了分析网站的用户行为，我们需要记录用户的访问日志。这些一条条的日志，可以看成是一条条的消息，我们可以将它们保存到消息队列中。将来有一些应用程序需要处理这些日志，就可以随时将这些消息取出来处理。</p>
<p>目前市面上的消息队列有很多，例如：Kafka、RabbitMQ、ActiveMQ、RocketMQ、ZeroMQ等。</p>
<h5 id="为什么叫Kafka呢"><a href="#为什么叫Kafka呢" class="headerlink" title="为什么叫Kafka呢"></a>为什么叫Kafka呢</h5><p>Kafka的架构师jay kreps非常喜欢franz kafka（弗兰兹·卡夫卡）,并且觉得kafka这个名字很酷，因此取了个和消息传递系统完全不相干的名称kafka，该名字并没有特别的含义。</p>
<p>「也就是说，你特别喜欢尼古拉斯赵四，将来你做一个项目，也可以把项目的名字取名为：尼古拉斯赵四，然后这个项目就火了」</p>
<h4 id="消息队列的应用场景"><a href="#消息队列的应用场景" class="headerlink" title="消息队列的应用场景"></a>消息队列的应用场景</h4><h5 id="异步处理"><a href="#异步处理" class="headerlink" title="异步处理"></a>异步处理</h5><p>电商网站中，新的用户注册时，需要将用户的信息保存到数据库中，同时还需要额外发送注册的邮件通知、以及短信注册码给用户。但因为发送邮件、发送注册短信需要连接外部的服务器，需要额外等待一段时间，此时，就可以使用消息队列来进行异步处理，从而实现快速响应。</p>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230220204957771.png" alt="image-20230220204957771"></p>
<h5 id="系统解耦"><a href="#系统解耦" class="headerlink" title="系统解耦"></a>系统解耦</h5><p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230220205100592.png" alt="image-20230220205100592"></p>
<h5 id="流量削峰"><a href="#流量削峰" class="headerlink" title="流量削峰"></a>流量削峰</h5><p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230220205155405.png" alt="image-20230220205155405"></p>
<h5 id="日志处理（大数据领域常见）"><a href="#日志处理（大数据领域常见）" class="headerlink" title="日志处理（大数据领域常见）"></a>日志处理（大数据领域常见）</h5><p>大型电商网站（淘宝、京东、国美、苏宁…）、App（抖音、美团、滴滴等）等需要分析用户行为，要根据用户的访问行为来发现用户的喜好以及活跃情况，需要在页面上收集大量的用户访问信息。</p>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230220205338436.png" alt="image-20230220205338436"></p>
<h4 id="生产者、消费者模型"><a href="#生产者、消费者模型" class="headerlink" title="生产者、消费者模型"></a>生产者、消费者模型</h4><p>我们之前学习过Java的服务器开发，Java服务器端开发的交互模型是这样的：</p>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230220205417595.png" alt="image-20230220205417595"></p>
<p>我们之前也学习过使用Java JDBC来访问操作MySQL数据库，它的交互模型是这样的：</p>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230220205444286.png" alt="image-20230220205444286"></p>
<p>它也是一种请求响应模型，只不过它不再是基于http协议，而是基于MySQL数据库的通信协议。</p>
<p>而如果我们基于消息队列来编程，此时的交互模式成为：生产者、消费者模型。</p>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230220205531093.png" alt="image-20230220205531093"></p>
<h4 id="消息队列的两种模式"><a href="#消息队列的两种模式" class="headerlink" title="消息队列的两种模式"></a>消息队列的两种模式</h4><h5 id="点对点模式"><a href="#点对点模式" class="headerlink" title="点对点模式"></a>点对点模式</h5><p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230220205611571.png" alt="image-20230220205611571"></p>
<p>消息发送者生产消息发送到消息队列中，然后消息接收者从消息队列中取出并且消费消息。消息被消费以后，消息队列中不再有存储，所以消息接收者不可能消费到已经被消费的消息。</p>
<p>点对点模式特点：</p>
<ul>
<li>每个消息只有一个接收者（Consumer）(即一旦被消费，消息就不再在消息队列中)</li>
<li>发送者和接收者间没有依赖性，发送者发送消息之后，不管有没有接收者在运行，都不会影响到发送者下次发送消息；</li>
<li>接收者在成功接收消息之后需向队列应答成功，以便消息队列删除当前接收的消息；</li>
</ul>
<h5 id="发布订阅模式"><a href="#发布订阅模式" class="headerlink" title="发布订阅模式"></a>发布订阅模式</h5><p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230220205821230.png" alt="image-20230220205821230"></p>
<p>发布/订阅模式特点：</p>
<ul>
<li>每个消息可以有多个订阅者；</li>
<li>发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息。</li>
<li>为了消费消息，订阅者需要提前订阅该角色主题，并保持在线运行；</li>
</ul>
<h3 id="Kafka简介"><a href="#Kafka简介" class="headerlink" title="Kafka简介"></a>Kafka简介</h3><h4 id="什么是Kafka"><a href="#什么是Kafka" class="headerlink" title="什么是Kafka"></a>什么是Kafka</h4><p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230220205954332.png" alt="image-20230220205954332"></p>
<p>Kafka是由Apache软件基金会开发的一个开源流平台，由Scala和Java编写。Kafka的Apache官网是这样介绍Kakfa的。</p>
<p>  Apache Kafka是一个分布式流平台。一个分布式的流平台应该包含3点关键的能力：  </p>
<ol>
<li>发布和订阅流数据流，类似于消息队列或者是企业消息传递系统  </li>
<li>以容错的持久化方式存储数据流  </li>
<li>处理数据流  </li>
</ol>
<h4 id="Kafka的应用场景"><a href="#Kafka的应用场景" class="headerlink" title="Kafka的应用场景"></a>Kafka的应用场景</h4><p>我们通常将Apache Kafka用在两类程序：</p>
<ol>
<li><p>建立实时数据管道，以可靠地在系统或应用程序之间获取数据</p>
</li>
<li><p>构建实时流应用程序，以转换或响应数据流</p>
</li>
</ol>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230220210211153.png" alt="image-20230220210211153"></p>
<p>上图，我们可以看到：</p>
<ol>
<li><p><code>Producers</code>：可以有很多的应用程序，将消息数据放入到Kafka集群中。</p>
</li>
<li><p><code>Consumers</code>：可以有很多的应用程序，将消息数据从Kafka集群中拉取出来。</p>
</li>
<li><p><code>Connectors</code>：Kafka的连接器可以将数据库中的数据导入到Kafka，也可以将Kafka的数据导出到</p>
</li>
</ol>
<p>数据库中。</p>
<ol start="4">
<li><code>Stream Processors</code>：流处理器可以Kafka中拉取数据，也可以将数据写入到Kafka中。</li>
</ol>
<h4 id="Kafka诞生背景"><a href="#Kafka诞生背景" class="headerlink" title="Kafka诞生背景"></a>Kafka诞生背景</h4><p>kafka的诞生，是为了解决linkedin的数据管道问题，起初linkedin采用了ActiveMQ来进行数据交换，大约是在2010年前后，那时的ActiveMQ还远远无法满足linkedin对数据传递系统的要求，经常由于各种缺陷而导致消息阻塞或者服务无法正常访问，为了能够解决这个问题，linkedin决定研发自己的消息传递系统，当时linkedin的首席架构师jay kreps便开始组织团队进行消息传递系统的研发。</p>
<p>提示：</p>
<ol>
<li>Linkedin还是挺牛逼的  </li>
<li> Kafka比ActiveMQ牛逼得多  </li>
</ol>
<h3 id="Kafka的优势"><a href="#Kafka的优势" class="headerlink" title="Kafka的优势"></a>Kafka的优势</h3><p>前面我们了解到，消息队列中间件有很多，为什么我们要选择Kafka？</p>
<table>
<thead>
<tr>
<th>特性</th>
<th>ActiveMQ</th>
<th>RabbitMQ</th>
<th>Kafka</th>
<th>RocketMQ</th>
</tr>
</thead>
<tbody><tr>
<td>所属社区/公司</td>
<td>Apache</td>
<td>Mozilla Public License</td>
<td>Apache</td>
<td>Apache/Ali</td>
</tr>
<tr>
<td>成熟度</td>
<td>成熟</td>
<td>成熟</td>
<td>成熟</td>
<td>比较成熟</td>
</tr>
<tr>
<td>生产者-消费者模式</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
</tr>
<tr>
<td>发布-订阅</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
</tr>
<tr>
<td>REQUEST-REPLY</td>
<td>支持</td>
<td>支持</td>
<td>-</td>
<td>支持</td>
</tr>
<tr>
<td>API完备性</td>
<td>高</td>
<td>高</td>
<td>高</td>
<td>低（静态配置）</td>
</tr>
<tr>
<td>多语言支持</td>
<td>支持JAVA优先</td>
<td>语言无关</td>
<td>支持，JAVA优先</td>
<td>支持</td>
</tr>
<tr>
<td>单机呑吐量</td>
<td>万级（最差）</td>
<td>万级</td>
<td><strong>十万级</strong></td>
<td>十万级（最高）</td>
</tr>
<tr>
<td>消息延迟</td>
<td>-</td>
<td>微秒级</td>
<td><strong>毫秒级</strong></td>
<td>-</td>
</tr>
<tr>
<td>可用性</td>
<td>高（主从）</td>
<td>高（主从）</td>
<td><strong>非常高（分布式）</strong></td>
<td>高</td>
</tr>
<tr>
<td>消息丢失</td>
<td>-</td>
<td>低</td>
<td><strong>理论上不会丢失</strong></td>
<td>-</td>
</tr>
<tr>
<td>消息重复</td>
<td>-</td>
<td>可控制</td>
<td>理论上会有重复</td>
<td>-</td>
</tr>
<tr>
<td>事务</td>
<td>支持</td>
<td>不支持</td>
<td>支持</td>
<td>支持</td>
</tr>
<tr>
<td>文档的完备性</td>
<td>高</td>
<td>高</td>
<td>高</td>
<td>中</td>
</tr>
<tr>
<td>提供快速入门</td>
<td>有</td>
<td>有</td>
<td>有</td>
<td>无</td>
</tr>
<tr>
<td>首次部署难度</td>
<td>-</td>
<td>低</td>
<td>中</td>
<td>高</td>
</tr>
</tbody></table>
<p>在大数据技术领域，一些重要的组件、框架都支持Apache Kafka，不论成成熟度、社区、性能、可靠性，Kafka都是非常有竞争力的一款产品。</p>
<h3 id="哪些公司在使用Kafka"><a href="#哪些公司在使用Kafka" class="headerlink" title="哪些公司在使用Kafka"></a>哪些公司在使用Kafka</h3><p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230220210752801.png" alt="image-20230220210752801"></p>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230220211406169.png" alt="image-20230220211406169"></p>
<h3 id="Kafka生态圈介绍"><a href="#Kafka生态圈介绍" class="headerlink" title="Kafka生态圈介绍"></a>Kafka生态圈介绍</h3><p>Apache Kafka这么多年的发展，目前也有一个较庞大的生态圈。</p>
<p>Kafka生态圈官网地址：<a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem">https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem</a></p>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230220211450569.png" alt="image-20230220211450569"></p>
<h3 id="Kafka版本"><a href="#Kafka版本" class="headerlink" title="Kafka版本"></a>Kafka版本</h3><p>本次课程使用的Kafka版本为2.4.1，是2020年3月12日发布的版本。</p>
<p>可以注意到Kafka的版本号为：kafka_2.12-2.4.1，因为kafka主要是使用scala语言开发的，2.12为scala的版本号。<a target="_blank" rel="noopener" href="http://kafka.apache.org/downloads%E5%8F%AF%E4%BB%A5%E6%9F%A5%E7%9C%8B%E5%88%B0%E6%AF%8F%E4%B8%AA%E7%89%88%E6%9C%AC%E7%9A%84%E5%8F%91%E5%B8%83%E6%97%B6%E9%97%B4%E3%80%82">http://kafka.apache.org/downloads可以查看到每个版本的发布时间。</a></p>
<h2 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h2><h3 id="搭建Kafka集群"><a href="#搭建Kafka集群" class="headerlink" title="搭建Kafka集群"></a>搭建Kafka集群</h3><p>以下基于ubuntu22.04.1</p>
<ol>
<li>将Kafka的安装包上传到虚拟机，并解压</li>
</ol>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230228164225219.png" alt="image-20230228164225219"></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir export</span><br><span class="line">cd /export</span><br><span class="line">sudo mkdir server</span><br><span class="line">sudo mkdir software</span><br><span class="line">sudo chmod 777 software/</span><br><span class="line">sudo chmod 777 server/</span><br><span class="line">cd /export/software/</span><br><span class="line">tar -xvzf kafka_2.12-2.4.1.tgz -C ../server/</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>修改 server.properties</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建Kafka数据的位置</span></span><br><span class="line">mkdir /export/server/kafka_2.12-2.4.1/data</span><br><span class="line">vim /export/server/kafka_2.12-2.4.1/config/server.properties</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">指定broker的<span class="built_in">id</span></span></span><br><span class="line">broker.id=0</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">指定Kafka数据的位置</span></span><br><span class="line">log.dirs=/export/server/kafka_2.12-2.4.1/data</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置zk的三个节点</span></span><br><span class="line">zookeeper.connect=10.211.55.8:2181,10.211.55.9:2181,10.211.55.7:2181</span><br></pre></td></tr></table></figure>

<p>其余两台服务器重复以上步骤,仅修改<code>broker.id</code></p>
<ol start="3">
<li>配置KAFKA_HOME环境变量</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sudo su</span><br><span class="line">vim /etc/profile</span><br><span class="line">export KAFKA_HOME=/export/server/kafka_2.12-2.4.1</span><br><span class="line">export PATH=:$PATH:$&#123;KAFKA_HOME&#125;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">源文件无下面这条需手动添加</span></span><br><span class="line">export PATH</span><br><span class="line"></span><br><span class="line">每个节点加载环境变量</span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>启动服务器</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动ZooKeeper 见黑马zookeeper集群搭建</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动Kafka,需要在kafka根目录下启动</span></span><br><span class="line">cd /export/server/kafka_2.12-2.4.1</span><br><span class="line">nohup bin/kafka-server-start.sh config/server.properties &amp;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试Kafka集群是否启动成功</span></span><br><span class="line">bin/kafka-topics.sh --bootstrap-server 10.211.55.8:9092 --list</span><br></pre></td></tr></table></figure>

<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230301160650636.png" alt="image-20230301160650636"></p>
<p>无任何报错即成功。</p>
<h3 id="目录结构分析"><a href="#目录结构分析" class="headerlink" title="目录结构分析"></a>目录结构分析</h3><table>
<thead>
<tr>
<th>目录名称</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>bin</td>
<td>Kafka的所有执行脚本都在这里。例如：启动Kafka服务器、创建Topic、生产者、消费者程序等等</td>
</tr>
<tr>
<td>config</td>
<td>Kafka的所有配置文件</td>
</tr>
<tr>
<td>libs</td>
<td>运行Kafka所需要的所有JAR包</td>
</tr>
<tr>
<td>logs</td>
<td>Kafka的所有日志文件，如果Kafka出现一些问题，需要到该目录中去查看异常信息</td>
</tr>
<tr>
<td>site-docs</td>
<td>Kafka的网站帮助文件</td>
</tr>
</tbody></table>
<h3 id="Kafka一键启动-关闭脚本"><a href="#Kafka一键启动-关闭脚本" class="headerlink" title="Kafka一键启动/关闭脚本"></a>Kafka一键启动/关闭脚本</h3><p>为了方便将来进行一键启动、关闭Kafka，我们可以编写一个shell脚本来操作。将来只要执行一次该脚本就可以快速启动/关闭Kafka。</p>
<ol>
<li>在节点1中创建 /export/onekey 目录</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir onekey</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>准备slave配置文件，用于保存要启动哪几个节点上的<strong>kafka</strong></li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cd /export/onekey</span><br><span class="line">sudo su</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">新建slave文件</span></span><br><span class="line">touch slave</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">slave中写入以下内容</span></span><br><span class="line">10.211.55.8</span><br><span class="line">10.211.55.9</span><br><span class="line">10.211.55.7</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>编写start-kafka.sh脚本</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">vim start-kafka.sh</span><br><span class="line"></span><br><span class="line">cat /export/onekey/slave | while read line</span><br><span class="line">do</span><br><span class="line">&#123;</span><br><span class="line"> echo $line</span><br><span class="line"> ssh $line &quot;source /etc/profile;export JMX_PORT=9988;nohup $&#123;KAFKA_HOME&#125;/bin/kafka-server-start.sh $&#123;KAFKA_HOME&#125;/config/server.properties &gt;/dev/nul* 2&gt;&amp;1 &amp; &quot;</span><br><span class="line"> wait</span><br><span class="line">&#125;&amp;</span><br><span class="line">done</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol start="4">
<li>编写stop-kafka.sh脚本</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">vim stop-kafka.sh</span><br><span class="line"></span><br><span class="line">cat /export/onekey/slave | while read line</span><br><span class="line">do</span><br><span class="line">&#123;</span><br><span class="line"> echo $line</span><br><span class="line"> ssh $line &quot;source /etc/profile;jps |grep Kafka |cut -d&#x27; &#x27; -f1 |xargs kill -s 9&quot;</span><br><span class="line"> wait</span><br><span class="line">&#125;&amp;</span><br><span class="line">done</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol start="5">
<li>给start-kafka.sh、stop-kafka.sh配置执行权限</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chmod u+x start-kafka.sh</span><br><span class="line">chmod u+x stop-kafka.sh</span><br></pre></td></tr></table></figure>

<ol start="6">
<li><p>执行一键启动、一键关闭</p>
<p>执行shell脚本需实现服务期间ssh免密登录</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u010044182/article/details/128664248">(69条消息) Ubuntu开启SSH免密登录_ubuntu配置ssh免密登录_天雪浪子的博客-CSDN博客</a></p>
</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./start-kafka.sh</span><br><span class="line">./stop-kafka.sh</span><br></pre></td></tr></table></figure>

<p>当查看日志发生<code>Error connecting to node ubuntu2:9092</code>错误时需在三台服务器上配置如下命令</p>
<p>以ubuntu2为例,另外两台同样的规则配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/hosts</span><br><span class="line"> </span><br><span class="line">10.211.55.8 ubuntu1</span><br><span class="line">10.211.55.7 ubuntu3</span><br></pre></td></tr></table></figure>

<h2 id="基础操作"><a href="#基础操作" class="headerlink" title="基础操作"></a>基础操作</h2><p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230302165113380.png" alt="image-20230302165113380"></p>
<h3 id="创建topic"><a href="#创建topic" class="headerlink" title="创建topic"></a>创建topic</h3><p>创建一个<code>topic</code>（主题）。Kafka中所有的消息都是保存在主题中，要生产消息到Kafka，首先必须要有一个确定的主题。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建名为<span class="built_in">test</span>的主题</span></span><br><span class="line">bin/kafka-topics.sh --create --bootstrap-server 10.211.55.8:9092 --topic test</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看目前Kafka中的主题</span></span><br><span class="line">bin/kafka-topics.sh --list --bootstrap-server 10.211.55.8:9092</span><br></pre></td></tr></table></figure>

<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230302165400395.png" alt="image-20230302165400395"></p>
<h3 id="生产消息到Kafka"><a href="#生产消息到Kafka" class="headerlink" title="生产消息到Kafka"></a>生产消息到Kafka</h3><p>使用Kafka内置的测试程序，生产一些消息到Kafka的<code>test</code>主题中。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-producer.sh --broker-list 10.211.55.8:9092 --topic test</span><br></pre></td></tr></table></figure>

<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230302165621183.png" alt="image-20230302165621183"></p>
<p>“&gt;”表示等待输入 </p>
<h3 id="从Kafka消费消息"><a href="#从Kafka消费消息" class="headerlink" title="从Kafka消费消息"></a>从Kafka消费消息</h3><p>使用下面的命令来消费 <code>test </code>主题中的消息。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --bootstrap-server 10.211.55.8:9092 --topic test --from-beginning</span><br></pre></td></tr></table></figure>

<p>生产者发送消息</p>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230302170001013.png" alt="image-20230302170001013"></p>
<p>消费者接受消息</p>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230302170027164.png" alt="image-20230302170027164"></p>
<h3 id="使用Kafka-Tools操作Kafka"><a href="#使用Kafka-Tools操作Kafka" class="headerlink" title="使用Kafka Tools操作Kafka"></a>使用Kafka Tools操作Kafka</h3><h4 id="连接Kafka集群"><a href="#连接Kafka集群" class="headerlink" title="连接Kafka集群"></a>连接Kafka集群</h4><p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230302170825532.png" alt="image-20230302170825532"></p>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230302170838039.png" alt="image-20230302170838039"></p>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230302170847729.png" alt="image-20230302170847729"></p>
<h4 id="创建topic-1"><a href="#创建topic-1" class="headerlink" title="创建topic"></a>创建topic</h4><p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230302170951476.png" alt="image-20230302170951476"></p>
<p>mac系统需要修改本地host,否则topic节点打不开</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/hosts</span><br><span class="line"></span><br><span class="line">10.211.55.9     ubuntu1 #prl_hostonly shared</span><br><span class="line">10.211.55.8     ubuntu2 #prl_hostonly shared</span><br><span class="line">10.211.55.7     ubuntu3 #prl_hostonly shared</span><br></pre></td></tr></table></figure>

<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230302193124105.png" alt="image-20230302193124105"></p>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230302193259933.png" alt="image-20230302193259933"></p>
<h2 id="Kafka基准测试"><a href="#Kafka基准测试" class="headerlink" title="Kafka基准测试"></a>Kafka基准测试</h2><h3 id="基准测试"><a href="#基准测试" class="headerlink" title="基准测试"></a>基准测试</h3><p>基准<a target="_blank" rel="noopener" href="http://www.blogjava.net/qileilove/archive/2012/07/05/382241.html">测试</a>（benchmark testing）是一种测量和评估软件性能指标的活动。我们可以通过基准测试，了解到软件、硬件的性能水平。主要测试负载的执行时间、传输速度、吞吐量、资源占用率等。</p>
<h4 id="基于1个分区1个副本的基准测试"><a href="#基于1个分区1个副本的基准测试" class="headerlink" title="基于1个分区1个副本的基准测试"></a>基于1个分区1个副本的基准测试</h4><ol>
<li>测试步骤：</li>
<li>启动Kafka集群</li>
<li>创建一个1个分区1个副本的topic: benchmark</li>
<li>同时运行生产者、消费者基准测试程序</li>
<li>观察结果</li>
</ol>
<h5 id="创建topic-2"><a href="#创建topic-2" class="headerlink" title="创建topic"></a>创建topic</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --zookeeper ubuntu1:2181 --create --topic benchmark --partitions 1 --replication-factor 1</span><br></pre></td></tr></table></figure>

<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230302211748409.png" alt="image-20230302211748409"></p>
<h5 id="生产消息基准测试"><a href="#生产消息基准测试" class="headerlink" title="生产消息基准测试"></a>生产消息基准测试</h5><p>在生产环境中，推荐使用生产5000W消息，这样会性能数据会更准确些。为了方便测试，课程上演示测试500W的消息作为基准测试。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-producer-perf-test.sh --topic benchmark --num-records 5000000 --throughput -1 --record-size 1000 --producer-props bootstrap.servers=ubuntu1:9092,ubuntu2:9092,ubuntu3:9092 acks=1</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-producer-perf-test.sh </span><br><span class="line">--topic topic的名字</span><br><span class="line">--num-records	总共指定生产数据量（默认5000W）</span><br><span class="line">--throughput	指定吞吐量——限流（-1不指定）</span><br><span class="line">--record-size   record数据大小（字节）</span><br><span class="line">--producer-props bootstrap.servers=192.168.1.20:9092,192.168.1.21:9092,192.168.1.22:9092 acks=1 指定Kafka集群地址，ACK模式</span><br></pre></td></tr></table></figure>

<p>测试结果</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu1:/export/server/kafka_2.bin/kafka-producer-perf-test.sh --topic benchmark --num-records 5000000 --throughput -1 --record-size 1000 --producer-props bootstrap.servers=ubuntu1:9092,ubuntu2:9092,ubuntu3:9092 acks=1092 acks=1</span><br><span class="line">237649 records sent, 47529.8 records/sec (45.33 MB/sec), 597.6 ms avg latency, 819.0 ms max latency.</span><br><span class="line">221936 records sent, 44387.2 records/sec (42.33 MB/sec), 738.2 ms avg latency, 805.0 ms max latency.</span><br><span class="line">309552 records sent, 61910.4 records/sec (59.04 MB/sec), 540.4 ms avg latency, 785.0 ms max latency.</span><br><span class="line">291008 records sent, 58062.3 records/sec (55.37 MB/sec), 572.4 ms avg latency, 760.0 ms max latency.</span><br><span class="line">289072 records sent, 57814.4 records/sec (55.14 MB/sec), 562.1 ms avg latency, 782.0 ms max latency.</span><br><span class="line">450960 records sent, 90192.0 records/sec (86.01 MB/sec), 368.3 ms avg latency, 546.0 ms max latency.</span><br><span class="line">417168 records sent, 83433.6 records/sec (79.57 MB/sec), 392.7 ms avg latency, 646.0 ms max latency.</span><br><span class="line">443296 records sent, 88659.2 records/sec (84.55 MB/sec), 369.7 ms avg latency, 475.0 ms max latency.</span><br><span class="line">455920 records sent, 91184.0 records/sec (86.96 MB/sec), 354.5 ms avg latency, 640.0 ms max latency.</span><br><span class="line">476384 records sent, 95276.8 records/sec (90.86 MB/sec), 348.9 ms avg latency, 622.0 ms max latency.</span><br><span class="line">464896 records sent, 92979.2 records/sec (88.67 MB/sec), 351.9 ms avg latency, 574.0 ms max latency.</span><br><span class="line">454288 records sent, 90857.6 records/sec (86.65 MB/sec), 360.8 ms avg latency, 445.0 ms max latency.</span><br><span class="line">478912 records sent, 95782.4 records/sec (91.35 MB/sec), 341.4 ms avg latency, 399.0 ms max latency.</span><br><span class="line">5000000 records sent, 76782.505874 records/sec (73.23 MB/sec), 423.57 ms avg latency, 819.00 ms max latency, 354 ms 50th, 727 ms 95th, 779 ms 99th, 800 ms 99.9th.</span><br></pre></td></tr></table></figure>

<p>测试结果：</p>
<table>
<thead>
<tr>
<th>吞吐量</th>
<th><strong>76782.505874 records/sec   每秒9.3W条记录</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>吞吐速率</strong></td>
<td><strong>(73.23 MB/sec)  每秒约89MB数据</strong></td>
</tr>
<tr>
<td><strong>平均延迟时间</strong></td>
<td><strong>423.57 ms avg latency</strong></td>
</tr>
<tr>
<td><strong>最大延迟时间</strong></td>
<td><strong>819.00 ms max latency</strong></td>
</tr>
</tbody></table>
<h5 id="消费消息基准测试"><a href="#消费消息基准测试" class="headerlink" title="消费消息基准测试"></a>消费消息基准测试</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-consumer-perf-test.sh --broker-list ubuntu1:9092,ubuntu2:9092,ubuntu3:9092 --topic benchmark --fetch-size 1048576 --messages 5000000</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-consumer-perf-test.sh</span><br><span class="line">--broker-list 指定kafka集群地址</span><br><span class="line">--topic 指定topic的名称</span><br><span class="line">--fetch-size 每次拉取的数据大小</span><br><span class="line">--messages 总共要消费的消息个数</span><br></pre></td></tr></table></figure>

<p>测试结果</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu1:/export/server/kafka_2.bin/kafka-consumer-perf-test.sh --broker-list ubuntu1:9092,ubuntu2:9092,ubuntu3:9092 --topic benchmark --fetch-size 1048576 --messages 5000000es 500start.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec</span><br><span class="line">2023-03-02 13:32:03:115, 2023-03-02 13:32:16:727, 4768.3716, 350.3065, 5000000, 367322.9503, 1677763923405, -1677763909793, -0.0000, -0.0030</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>data.consumed.in.MB  共计消费的数据</th>
<th><strong>4768.3716MB</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>MB.sec  每秒消费的数量</strong></td>
<td><strong>350.3065  每秒350MB</strong></td>
</tr>
<tr>
<td><strong>data.consumed.in.nMsg  共计消费的数量</strong></td>
<td><strong>5000000</strong></td>
</tr>
<tr>
<td><strong>nMsg.sec  每秒的数量</strong></td>
<td><strong>367322.9503  每秒36.7W条</strong></td>
</tr>
</tbody></table>
<h4 id="基于3个分区1个副本的基准测试"><a href="#基于3个分区1个副本的基准测试" class="headerlink" title="基于3个分区1个副本的基准测试"></a>基于3个分区1个副本的基准测试</h4><h5 id="创建topic-3"><a href="#创建topic-3" class="headerlink" title="创建topic"></a>创建topic</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --zookeeper ubuntu1:2181 --create --topic benchmark --partitions 3 --replication-factor 1</span><br></pre></td></tr></table></figure>

<h5 id="生产消息基准测试-1"><a href="#生产消息基准测试-1" class="headerlink" title="生产消息基准测试"></a>生产消息基准测试</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-producer-perf-test.sh --topic benchmark --num-records 5000000 --throughput -1 --record-size 1000 --producer-props bootstrap.servers=ubuntu1:9092,ubuntu2:9092,ubuntu3:9092 acks=1</span><br></pre></td></tr></table></figure>

<p>测试结果</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu1:/export/server/kafka_2.bin/kafka-producer-perf-test.sh --topic benchmark --num-records 5000000 --throughput -1 --record-size 1000 --producer-props bootstrap.servers=ubuntu1:9092,ubuntu2:9092,ubuntu3:9092 acks=1092 acks=1</span><br><span class="line">484241 records sent, 96848.2 records/sec (92.36 MB/sec), 288.7 ms avg latency, 703.0 ms max latency.</span><br><span class="line">450722 records sent, 90144.4 records/sec (85.97 MB/sec), 351.9 ms avg latency, 1714.0 ms max latency.</span><br><span class="line">812375 records sent, 162475.0 records/sec (154.95 MB/sec), 208.1 ms avg latency, 1160.0 ms max latency.</span><br><span class="line">934223 records sent, 186844.6 records/sec (178.19 MB/sec), 176.9 ms avg latency, 752.0 ms max latency.</span><br><span class="line">691132 records sent, 138226.4 records/sec (131.82 MB/sec), 237.0 ms avg latency, 839.0 ms max latency.</span><br><span class="line">706355 records sent, 141073.5 records/sec (134.54 MB/sec), 225.9 ms avg latency, 858.0 ms max latency.</span><br><span class="line">592279 records sent, 118455.8 records/sec (112.97 MB/sec), 277.3 ms avg latency, 1594.0 ms max latency.</span><br><span class="line">5000000 records sent, 133911.832450 records/sec (127.71 MB/sec), 240.60 ms avg latency, 1714.00 ms max latency, 18 ms 50th, 797 ms 95th, 1493 ms 99th, 1694 ms 99.9th.</span><br></pre></td></tr></table></figure>

<p>测试结果：</p>
<table>
<thead>
<tr>
<th><strong>指标</strong></th>
<th><strong>3</strong>分区1个副本</th>
<th><strong>单分区单副本</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>吞吐量</strong></td>
<td><strong>133911.832450 records/sec</strong></td>
<td><strong>76782.505874 records/sec   每秒9.3W条记录</strong></td>
</tr>
<tr>
<td><strong>吞吐速率</strong></td>
<td><strong>127.71 MB/sec</strong></td>
<td><strong>(73.23 MB/sec)  每秒约89MB数据</strong></td>
</tr>
<tr>
<td><strong>平均延迟时间</strong></td>
<td><strong>240.60 ms avg latency</strong></td>
<td><strong>423.57 ms avg latency</strong></td>
</tr>
<tr>
<td><strong>最大延迟时间</strong></td>
<td><strong>1714.00 ms max latency</strong></td>
<td><strong>819.00 ms max latency</strong></td>
</tr>
</tbody></table>
<p>在虚拟机上，因为都是共享笔记本上的CPU、内存、网络，所以分区越多，反而效率越低。但如果是真实的服务器，分区多效率是会有明显提升的。</p>
<h5 id="消费消息基准测试-1"><a href="#消费消息基准测试-1" class="headerlink" title="消费消息基准测试"></a>消费消息基准测试</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-consumer-perf-test.sh --broker-list ubuntu1:9092,ubuntu2:9092,ubuntu3:9092 --topic benchmark --fetch-size 1048576 --messages 5000000</span><br></pre></td></tr></table></figure>

<p>测试结果</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu1:/export/server/kafka_2.bin/kafka-consumer-perf-test.sh --broker-list ubuntu1:9092,ubuntu2:9092,ubuntu3:9092 --topic benchmark --fetch-size 1048576 --messages 5000000es 500start.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec</span><br><span class="line">2023-03-02 13:44:10:033, 2023-03-02 13:44:22:711, 4768.3716, 376.1139, 5000000, 394383.9722, 1677764650317, -1677764637639, -0.0000, -0.0030</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th><strong>指标</strong></th>
<th><strong>单分区3个副本</strong></th>
<th><strong>单分区单副本</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>data.consumed.in.MB  共计消费的数据</strong></td>
<td><strong>4768.3716</strong> MB</td>
<td><strong>4768.3716MB    4768.3716MB</strong></td>
</tr>
<tr>
<td><strong>MB.sec  每秒消费的数量</strong></td>
<td><strong>376.1139</strong></td>
<td><strong>350.3065  每秒350MB    445.6006  每秒445MB</strong></td>
</tr>
<tr>
<td><strong>data.consumed.in.nMsg  共计消费的数量</strong></td>
<td><strong>5000000</strong></td>
<td><strong>5000000</strong></td>
</tr>
<tr>
<td><strong>nMsg.sec  每秒的数量</strong></td>
<td><strong>394383.9722</strong></td>
<td><strong>367322.9503  每秒36.7W条</strong></td>
</tr>
</tbody></table>
<p>虽然是虚拟机 mac就是牛依然是提升的</p>
<h4 id="基于1个分区3个副本的基准测试"><a href="#基于1个分区3个副本的基准测试" class="headerlink" title="基于1个分区3个副本的基准测试"></a>基于1个分区3个副本的基准测试</h4><h5 id="创建topic-4"><a href="#创建topic-4" class="headerlink" title="创建topic"></a>创建topic</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --zookeeper ubuntu1:2181 --create --topic benchmark --partitions 1 --replication-factor 3</span><br></pre></td></tr></table></figure>

<h5 id="生产消息基准测试-2"><a href="#生产消息基准测试-2" class="headerlink" title="生产消息基准测试"></a>生产消息基准测试</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-producer-perf-test.sh --topic benchmark --num-records 5000000 --throughput -1 --record-size 1000 --producer-props bootstrap.servers=ubuntu1:9092,ubuntu2:9092,ubuntu3:9092 acks=1</span><br></pre></td></tr></table></figure>

<p>测试结果：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu1:/export/server/kafka_2.bin/kafka-producer-perf-test.sh --topic benchmark --num-records 5000000 --throughput -1 --record-size 1000 --producer-props bootstrap.servers=ubuntu1:9092,ubuntu2:9092,ubuntu3:9092 acks=1092 acks=1</span><br><span class="line">145345 records sent, 29069.0 records/sec (27.72 MB/sec), 926.1 ms avg latency, 1293.0 ms max latency.</span><br><span class="line">242256 records sent, 48451.2 records/sec (46.21 MB/sec), 684.4 ms avg latency, 907.0 ms max latency.</span><br><span class="line">163568 records sent, 32713.6 records/sec (31.20 MB/sec), 979.1 ms avg latency, 1229.0 ms max latency.</span><br><span class="line">248480 records sent, 49696.0 records/sec (47.39 MB/sec), 675.7 ms avg latency, 971.0 ms max latency.</span><br><span class="line">229616 records sent, 45923.2 records/sec (43.80 MB/sec), 706.5 ms avg latency, 868.0 ms max latency.</span><br><span class="line">171936 records sent, 34387.2 records/sec (32.79 MB/sec), 840.2 ms avg latency, 1756.0 ms max latency.</span><br><span class="line">186592 records sent, 37318.4 records/sec (35.59 MB/sec), 982.8 ms avg latency, 1830.0 ms max latency.</span><br><span class="line">120368 records sent, 24064.0 records/sec (22.95 MB/sec), 1030.1 ms avg latency, 2565.0 ms max latency.</span><br><span class="line">187792 records sent, 37558.4 records/sec (35.82 MB/sec), 1073.2 ms avg latency, 2860.0 ms max latency.</span><br><span class="line">226480 records sent, 45296.0 records/sec (43.20 MB/sec), 748.3 ms avg latency, 1209.0 ms max latency.</span><br><span class="line">167728 records sent, 33545.6 records/sec (31.99 MB/sec), 948.7 ms avg latency, 1645.0 ms max latency.</span><br><span class="line">159312 records sent, 31862.4 records/sec (30.39 MB/sec), 1037.4 ms avg latency, 1410.0 ms max latency.</span><br><span class="line">134400 records sent, 26880.0 records/sec (25.63 MB/sec), 1225.2 ms avg latency, 2018.0 ms max latency.</span><br><span class="line">208432 records sent, 41678.1 records/sec (39.75 MB/sec), 779.9 ms avg latency, 886.0 ms max latency.</span><br><span class="line">185632 records sent, 37119.0 records/sec (35.40 MB/sec), 862.7 ms avg latency, 1511.0 ms max latency.</span><br><span class="line">202528 records sent, 40505.6 records/sec (38.63 MB/sec), 842.9 ms avg latency, 1159.0 ms max latency.</span><br><span class="line">237680 records sent, 47536.0 records/sec (45.33 MB/sec), 691.4 ms avg latency, 865.0 ms max latency.</span><br><span class="line">223792 records sent, 44678.0 records/sec (42.61 MB/sec), 715.1 ms avg latency, 863.0 ms max latency.</span><br><span class="line">229936 records sent, 45987.2 records/sec (43.86 MB/sec), 730.5 ms avg latency, 1010.0 ms max latency.</span><br><span class="line">260544 records sent, 52108.8 records/sec (49.69 MB/sec), 626.3 ms avg latency, 686.0 ms max latency.</span><br><span class="line">211824 records sent, 42364.8 records/sec (40.40 MB/sec), 779.5 ms avg latency, 1792.0 ms max latency.</span><br><span class="line">294144 records sent, 58828.8 records/sec (56.10 MB/sec), 561.3 ms avg latency, 661.0 ms max latency.</span><br><span class="line">322064 records sent, 64412.8 records/sec (61.43 MB/sec), 508.8 ms avg latency, 570.0 ms max latency.</span><br><span class="line">5000000 records sent, 41859.219074 records/sec (39.92 MB/sec), 777.09 ms avg latency, 2860.00 ms max latency, 705 ms 50th, 1245 ms 95th, 1978 ms 99th, 2840 ms 99.9th.</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th align="center"><strong>指标</strong></th>
<th><strong>单分区3个副本</strong></th>
<th><strong>单分区单副本</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong>吞吐量</strong></td>
<td><strong>41859.219074 records/sec</strong></td>
<td><strong>76782.505874 records/sec   每秒9.3W条记录</strong></td>
</tr>
<tr>
<td align="center"><strong>吞吐速率</strong></td>
<td><strong>39.92 MB/sec</strong></td>
<td><strong>(73.23 MB/sec)  每秒约89MB数据</strong></td>
</tr>
<tr>
<td align="center"><strong>平均延迟时间</strong></td>
<td><strong>777.09 ms avg latency</strong></td>
<td><strong>423.57 ms avg latency</strong></td>
</tr>
<tr>
<td align="center"><strong>最大延迟时间</strong></td>
<td><strong>2860.00 ms max latency</strong></td>
<td><strong>819.00 ms max latency</strong></td>
</tr>
</tbody></table>
<p>同样的配置，副本越多速度越慢。</p>
<h5 id="消费消息基准测试-2"><a href="#消费消息基准测试-2" class="headerlink" title="消费消息基准测试"></a>消费消息基准测试</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-consumer-perf-test.sh --broker-list buntu1:9092,ubuntu2:9092,ubuntu3:9092 --topic benchmark --fetch-size 1048576 --messages 5000000</span><br></pre></td></tr></table></figure>

<p>测试结果</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu1:/export/server/kafka_2.bin/kafka-consumer-perf-test.sh --broker-list buntu1:9092,ubuntu2:9092,ubuntu3:9092 --topic benchmark --fetch-size 1048576 --messages 5000000es 5000start.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec</span><br><span class="line">[2023-03-02 13:55:39,901] WARN Couldn&#x27;t resolve server buntu1:9092 from bootstrap.servers as DNS resolution failed for buntu1 (org.apache.kafka.clients.ClientUtils)</span><br><span class="line">2023-03-02 13:55:39:945, 2023-03-02 13:55:55:180, 4768.3716, 312.9880, 5000000, 328191.6639, 1677765340146, -1677765324911, -0.0000, -0.0030</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th><strong>指标</strong></th>
<th><strong>单分区3个副本</strong></th>
<th><strong>单分区单副本</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>data.consumed.in.MB  共计消费的数据</strong></td>
<td><strong>4768.3716 MB</strong></td>
<td><strong>4768.3716MB    4768.3716MB</strong></td>
</tr>
<tr>
<td><strong>MB.sec  每秒消费的数量</strong></td>
<td><strong>312.9880</strong></td>
<td><strong>350.3065  每秒350MB    445.6006  每秒445MB</strong></td>
</tr>
<tr>
<td><strong>data.consumed.in.nMsg  共计消费的数量</strong></td>
<td><strong>5000000</strong></td>
<td><strong>5000000</strong></td>
</tr>
<tr>
<td><strong>nMsg.sec  每秒的数量</strong></td>
<td><strong>328191.6639</strong></td>
<td><strong>367322.9503  每秒36.7W条</strong></td>
</tr>
</tbody></table>
<h2 id="Java编程操作Kafka"><a href="#Java编程操作Kafka" class="headerlink" title="Java编程操作Kafka"></a>Java编程操作Kafka</h2><h3 id="同步生产消息到Kafka中"><a href="#同步生产消息到Kafka中" class="headerlink" title="同步生产消息到Kafka中"></a>同步生产消息到Kafka中</h3><h4 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h4><p>接下来，我们将编写Java程序，将1-100的数字消息写入到Kafka中。</p>
<h4 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h4><h5 id="导入Maven-Kafka-POM依赖"><a href="#导入Maven-Kafka-POM依赖" class="headerlink" title="导入Maven Kafka POM依赖"></a>导入Maven Kafka POM依赖</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">repositories</span>&gt;</span><span class="comment">&lt;!-- 代码库 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>central<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://maven.aliyun.com/nexus/content/groups/public//<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">releases</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">enabled</span>&gt;</span>true<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">releases</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">snapshots</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">enabled</span>&gt;</span>true<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">updatePolicy</span>&gt;</span>always<span class="tag">&lt;/<span class="name">updatePolicy</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">checksumPolicy</span>&gt;</span>fail<span class="tag">&lt;/<span class="name">checksumPolicy</span>&gt;</span></span><br><span class="line"> 				<span class="tag">&lt;/<span class="name">snapshots</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">repositories</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- kafka客户端工具 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 工具类 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.commons<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-io<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.3.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- SLF桥接LOG4J日志 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-log4j12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- SLOG4J日志 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.16<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.7.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">        				<span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="导入log4j-properties"><a href="#导入log4j-properties" class="headerlink" title="导入log4j.properties"></a>导入log4j.properties</h5><p>将log4j.properties配置文件放入到resources文件夹中</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">log4j.rootLogger</span>=<span class="string">INFO,stdout</span></span><br><span class="line"><span class="attr">log4j.appender.stdout</span>=<span class="string">org.apache.log4j.ConsoleAppender </span></span><br><span class="line"><span class="attr">log4j.appender.stdout.layout</span>=<span class="string">org.apache.log4j.PatternLayout </span></span><br><span class="line"><span class="attr">log4j.appender.stdout.layout.ConversionPattern</span>=<span class="string">%5p - %m%n</span></span><br></pre></td></tr></table></figure>

<h5 id="创建包和类"><a href="#创建包和类" class="headerlink" title="创建包和类"></a>创建包和类</h5><p>创建包<code>cn.itcast.kafka</code>，并创建<code>KafkaProducerTest</code>类。</p>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230303164943795.png" alt="image-20230303164943795"></p>
<h4 id="代码开发"><a href="#代码开发" class="headerlink" title="代码开发"></a>代码开发</h4><p>可以参考以下方式来编写第一个Kafka示例程序</p>
<p>参考以下文档：<a target="_blank" rel="noopener" href="http://kafka.apache.org/24/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html">http://kafka.apache.org/24/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html</a></p>
<ol>
<li>创建用于连接Kafka的Properties配置</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Properties</span> <span class="variable">props</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">props.put(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;192.168.88.100:9092&quot;</span>);</span><br><span class="line"><span class="comment">//这个配置是 Kafka 生产者和消费者必须要指定的一个配置项，它用于指定 Kafka 集群中的一个或多个 broker 地址，生产者和消费者将使用这些地址与 Kafka 集群建立连接。</span></span><br><span class="line">props.put(<span class="string">&quot;acks&quot;</span>, <span class="string">&quot;all&quot;</span>);</span><br><span class="line"><span class="comment">//这行代码将 acks 配置设置为 all。acks 配置用于指定消息确认的级别。在此配置下，生产者将等待所有副本都成功写入后才会认为消息发送成功。这种配置级别可以确保数据不会丢失，但可能会影响性能。</span></span><br><span class="line">props.put(<span class="string">&quot;key.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line"><span class="comment">//这行代码将键（key）序列化器的类名设置为 org.apache.kafka.common.serialization.StringSerializer。键和值都需要被序列化以便于在网络上传输。这里使用的是一个字符串序列化器，它将字符串序列化为字节数组以便于发送到 Kafka 集群。</span></span><br><span class="line">props.put(<span class="string">&quot;value.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line"><span class="comment">//这行代码将值（value）序列化器的类名设置为 org.apache.kafka.common.serialization.StringSerializer。这里同样使用的是一个字符串序列化器，它将字符串序列化为字节数组以便于发送到 Kafka 集群。</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>创建一个生产者对象<code>KafkaProducer</code></li>
<li>调用send发送1-100消息到指定Topic test，并获取返回值Future，该对象封装了返回值</li>
<li>再调用一个<code>Future.get()</code>方法等待响应</li>
<li>关闭生产者</li>
</ol>
<p>参考代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KafkaProducerTest</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1. 创建用于连接Kafka的Properties配置</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">props</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        props.put(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;192.168.88.100:9092&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;acks&quot;</span>, <span class="string">&quot;all&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;key.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;value.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建一个生产者对象KafkaProducer</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; producer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;String, String&gt;(props);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 调用send发送1-100消息到指定Topic test</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">100</span>; ++i) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="comment">// 获取返回值Future，该对象封装了返回值</span></span><br><span class="line">                Future&lt;RecordMetadata&gt; future = producer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;String, String&gt;(<span class="string">&quot;test&quot;</span>, <span class="literal">null</span>, i + <span class="string">&quot;&quot;</span>));</span><br><span class="line">              <span class="comment">//&quot;test&quot;：这个参数是指定 Kafka 主题（topic）的名称，表示这条记录将被发送到哪个主题中。</span></span><br><span class="line">              <span class="comment">//null：这个参数表示记录的键（key）。在 Kafka 中，每条消息都可以有一个键值对，键是一个可选参数，如果没有设置，则为 null。</span></span><br><span class="line">              <span class="comment">//i + &quot;&quot;：这个参数表示记录的值（value）。这里的 i 是一个整数，通过将它转换为字符串来设置记录的值。这个值将被序列化为字节数组并被发送到 Kafka 集群。</span></span><br><span class="line"></span><br><span class="line">综上所述，这行代码的含义是：创建一个 Kafka 生产者记录对象，将该记录的值设置为 i 的字符串形式，并指定该记录将被发送到名为 <span class="string">&quot;test&quot;</span> 的主题中，键为 <span class="literal">null</span>。</span><br><span class="line">                <span class="comment">// 调用一个Future.get()方法等待响应</span></span><br><span class="line">                future.get();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (ExecutionException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5. 关闭生产者</span></span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>测试：</p>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230303165351697.png" alt="image-20230303165351697"></p>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230303165432474.png" alt="image-20230303165432474"></p>
<h3 id="从Kafka的topic中消费消息"><a href="#从Kafka的topic中消费消息" class="headerlink" title="从Kafka的topic中消费消息"></a>从Kafka的topic中消费消息</h3><h4 id="需求-1"><a href="#需求-1" class="headerlink" title="需求"></a>需求</h4><p>从 test topic中，将消息都消费，并将记录的offset、key、value打印出来</p>
<h4 id="准备工作-1"><a href="#准备工作-1" class="headerlink" title="准备工作"></a>准备工作</h4><p>在cn.itcast.kafka包下创建<code>KafkaConsumerTest</code>类</p>
<h4 id="开发步骤"><a href="#开发步骤" class="headerlink" title="开发步骤"></a>开发步骤</h4><ol>
<li>创建Kafka消费者配置</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Properties</span> <span class="variable">props</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">props.setProperty(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;node1.itcast.cn:9092&quot;</span>);</span><br><span class="line"><span class="comment">//这一行将属性&quot;bootstrap.servers&quot;的值设置为&quot;node1.itcast.cn:9092&quot;。这是Kafka生产者和消费者所需的Kafka集群地址和端口号。</span></span><br><span class="line">props.setProperty(<span class="string">&quot;group.id&quot;</span>, <span class="string">&quot;test&quot;</span>);</span><br><span class="line"><span class="comment">//这一行将属性&quot;group.id&quot;的值设置为&quot;test&quot;。这是消费者组的唯一标识符。所有属于同一组的消费者将共享一个消费者组ID。</span></span><br><span class="line">props.setProperty(<span class="string">&quot;enable.auto.commit&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line"><span class="comment">//这一行将属性&quot;enable.auto.commit&quot;的值设置为&quot;true&quot;。这表示消费者是否应该自动提交偏移量。</span></span><br><span class="line">props.setProperty(<span class="string">&quot;auto.commit.interval.ms&quot;</span>, <span class="string">&quot;1000&quot;</span>);</span><br><span class="line"><span class="comment">//这一行将属性&quot;auto.commit.interval.ms&quot;的值设置为&quot;1000&quot;。这是消费者自动提交偏移量的时间间隔，以毫秒为单位。</span></span><br><span class="line">props.setProperty(<span class="string">&quot;key.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">props.setProperty(<span class="string">&quot;value.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line"><span class="comment">//这两行将属性&quot;key.deserializer&quot;和&quot;value.deserializer&quot;的值都设置为&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;。这是用于反序列化Kafka消息的Java类的名称。在这种情况下，消息的键和值都是字符串类型，因此使用了StringDeserializer类来反序列化它们。</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>创建Kafka消费者</li>
<li>订阅要消费的主题</li>
<li>使用一个while循环，不断从Kafka的topic中拉取消息</li>
<li>将将记录（record）的offset、key、value都打印出来</li>
</ol>
<h4 id="参考代码"><a href="#参考代码" class="headerlink" title="参考代码"></a>参考代码</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.itcast.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.time.Duration;</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KafkaConsumerTest</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Properties</span> <span class="variable">props</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        props.setProperty(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;10.211.55.8:9092&quot;</span>);</span><br><span class="line">        props.setProperty(<span class="string">&quot;group.id&quot;</span>, <span class="string">&quot;test&quot;</span>);</span><br><span class="line">        props.setProperty(<span class="string">&quot;enable.auto.commit&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line">        props.setProperty(<span class="string">&quot;auto.commit.interval.ms&quot;</span>, <span class="string">&quot;1000&quot;</span>);</span><br><span class="line">        props.setProperty(<span class="string">&quot;key.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        props.setProperty(<span class="string">&quot;value.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建kafka消费者</span></span><br><span class="line">        <span class="type">KafkaConsumer</span> <span class="variable">kafkaConsumer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;&gt;(props);</span><br><span class="line">        <span class="comment">//订阅要消费的主题</span></span><br><span class="line">        <span class="comment">//指定消费者从哪个topic中拉取数据</span></span><br><span class="line">        kafkaConsumer.subscribe(Arrays.asList(<span class="string">&quot;test&quot;</span>));</span><br><span class="line">        <span class="comment">//使用一个while循环，不断从kafka的topic中拉取消息</span></span><br><span class="line">        <span class="keyword">while</span>(<span class="literal">true</span>)&#123;</span><br><span class="line">            <span class="comment">//kafka一次拉取一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String,String&gt; poll = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">5</span>));</span><br><span class="line">            <span class="comment">//将记录record的offset、key、value都打印出来</span></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String,String&gt;consumerRecord:poll)&#123;</span><br><span class="line">                <span class="comment">//主题</span></span><br><span class="line">                <span class="type">String</span> <span class="variable">topic</span> <span class="operator">=</span> consumerRecord.topic();</span><br><span class="line">                <span class="comment">//offset:这条消息处于kafka分区中的哪个位置</span></span><br><span class="line">                <span class="type">long</span> offset=consumerRecord.offset();</span><br><span class="line">                <span class="comment">//key\value</span></span><br><span class="line">                String key=consumerRecord.key();</span><br><span class="line">                String value=consumerRecord.value();</span><br><span class="line">                System.out.println(<span class="string">&quot;topic:&quot;</span>+topic+<span class="string">&quot;offset:&quot;</span>+offset+<span class="string">&quot;key:&quot;</span>+key+<span class="string">&quot;value:&quot;</span>+value);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>启动消费者，定位到最新的offset</p>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230303174132218.png" alt="image-20230303174132218"></p>
<p>生产者再次发送消息，观察消费者变化</p>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230303174248747.png" alt="image-20230303174248747"></p>
<h3 id="异步使用带有回调函数方法生产消息"><a href="#异步使用带有回调函数方法生产消息" class="headerlink" title="异步使用带有回调函数方法生产消息"></a>异步使用带有回调函数方法生产消息</h3><p>如果我们想获取生产者消息是否成功，或者成功生产消息到<code>Kafka</code>中后，执行一些其他动作。此时，可以很方便地使用带有回调函数来发送消息。</p>
<p>需求：</p>
<ol>
<li>在发送消息出现异常时，能够及时打印出异常信息</li>
<li>在发送消息成功时，打印Kafka的topic名字、分区id、offset</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.itcast.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.Callback;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.RecordMetadata;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ExecutionException;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Future;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KafkaProducerTest</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1. 创建用于连接Kafka的Properties配置</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">props</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        props.put(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;node1.itcast.cn:9092&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;acks&quot;</span>, <span class="string">&quot;all&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;key.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;value.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建一个生产者对象KafkaProducer</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; producer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;String, String&gt;(props);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 调用send发送1-100消息到指定Topic test</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">100</span>; ++i) &#123;</span><br><span class="line">            <span class="comment">// 一、同步方式</span></span><br><span class="line">            <span class="comment">// 获取返回值Future，该对象封装了返回值</span></span><br><span class="line">            <span class="comment">// Future&lt;RecordMetadata&gt; future = producer.send(new ProducerRecord&lt;String, String&gt;(&quot;test&quot;, null, i + &quot;&quot;));</span></span><br><span class="line">            <span class="comment">// 调用一个Future.get()方法等待响应</span></span><br><span class="line">            <span class="comment">// future.get();</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">// 二、带回调函数异步方式</span></span><br><span class="line">            producer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;String, String&gt;(<span class="string">&quot;test&quot;</span>, <span class="literal">null</span>, i + <span class="string">&quot;&quot;</span>), <span class="keyword">new</span> <span class="title class_">Callback</span>() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span> &#123;</span><br><span class="line">                    <span class="keyword">if</span>(exception != <span class="literal">null</span>) &#123;</span><br><span class="line">                        System.out.println(<span class="string">&quot;发送消息出现异常&quot;</span>);</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">else</span> &#123;</span><br><span class="line">                        <span class="type">String</span> <span class="variable">topic</span> <span class="operator">=</span> metadata.topic();</span><br><span class="line">                        <span class="type">int</span> <span class="variable">partition</span> <span class="operator">=</span> metadata.partition();</span><br><span class="line">                        <span class="type">long</span> <span class="variable">offset</span> <span class="operator">=</span> metadata.offset();</span><br><span class="line"></span><br><span class="line">                        System.out.println(<span class="string">&quot;发送消息到Kafka中的名字为&quot;</span> + topic + <span class="string">&quot;的主题，第&quot;</span> + partition + <span class="string">&quot;分区，第&quot;</span> + offset + <span class="string">&quot;条数据成功!&quot;</span>);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5. 关闭生产者</span></span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230304125250709.png" alt="image-20230304125250709"></p>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><h3 id="Kafka重要概念"><a href="#Kafka重要概念" class="headerlink" title="Kafka重要概念"></a>Kafka重要概念</h3><h4 id="broker"><a href="#broker" class="headerlink" title="broker"></a>broker</h4><p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230304125417711.png" alt="image-20230304125417711"></p>
<ol>
<li> 一个Kafka的集群通常由多个<code>broker</code>组成，这样才能实现负载均衡、以及容错</li>
<li><code>broker</code>是<code>无状态（Sateless</code>的，它们是通过<code>ZooKeeper</code>来维护集群状态</li>
<li>一个Kafka的<code>broker</code>每秒可以处理数十万次读写，每个<code>broker</code>都可以处理TB消息而不影响性能</li>
</ol>
<h4 id="zookeeper"><a href="#zookeeper" class="headerlink" title="zookeeper"></a>zookeeper</h4><p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230304125745530.png" alt="image-20230304125745530"></p>
<ol>
<li>ZK用来管理和协调<code>broker</code>，并且存储了Kafka的元数据（例如：有多少topic、partition、consumer）</li>
<li>ZK服务主要用于通知生产者和消费者Kafka集群中有新的<code>broker</code>加入、或者Kafka集群中出现故障的<code>broker</code>。</li>
</ol>
<p>PS：Kafka正在逐步想办法将ZooKeeper剥离，维护两套集群成本较高，社区提出KIP-500就是要替换掉ZooKeeper的依赖。“Kafka on Kafka”——Kafka自己来管理自己的元数据</p>
<h4 id="producer（生产者）"><a href="#producer（生产者）" class="headerlink" title="producer（生产者）"></a>producer（生产者）</h4><p>生产者负责将数据推送给<code>broker</code>的<code>topic</code></p>
<h4 id="consumer（消费者）"><a href="#consumer（消费者）" class="headerlink" title="consumer（消费者）"></a>consumer（消费者）</h4><p>消费者负责从<code>broker</code>的<code>topic</code>中拉取数据，并自己进行处理</p>
<h4 id="consumer-group（消费者组）"><a href="#consumer-group（消费者组）" class="headerlink" title="consumer group（消费者组）"></a>consumer group（消费者组）</h4><p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230304125938966.png" alt="image-20230304125938966"></p>
<ul>
<li><code>consumer group</code>是kafka提供的可扩展且具有容错性的消费者机制</li>
<li>一个消费者组可以包含多个消费者</li>
<li>一个消费者组有一个唯一的ID（group Id）</li>
<li>组内的消费者一起消费主题的所有分区数据</li>
</ul>
<h4 id="分区（Partitions）"><a href="#分区（Partitions）" class="headerlink" title="分区（Partitions）"></a>分区（Partitions）</h4><p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230304130211916.png" alt="image-20230304130211916"></p>
<p>在Kafka集群中，主题被分为多个分区</p>
<p>在 Kafka 中，同一个 topic 的消息可以被分配到不同的分区中，具体分配规则取决于 partitioner。</p>
<p>Kafka 提供了默认的 partitioner 实现，称为 DefaultPartitioner，其将消息的 key（如果存在）进行哈希，然后根据哈希值确定该消息应该被分配到哪个分区。如果消息没有 key，则采用轮询的方式将消息分配到不同的分区中。</p>
<p>除了默认的 partitioner，用户还可以自定义 partitioner 实现，以满足不同的需求。自定义 partitioner 实现需要实现 Kafka 提供的 Partitioner 接口，并在生产者配置中指定使用该 partitioner。</p>
<p>无论是使用默认的 partitioner 还是自定义 partitioner，都需要遵循以下规则：</p>
<ul>
<li>对于同一个 key，始终分配到同一个分区中。</li>
<li>对于没有 key 的消息，应该采用随机或轮询的方式将消息分配到不同的分区中。</li>
</ul>
<p>需要注意的是，分区数的变化也可能导致消息分配到不同的分区中。例如，当某个 topic 的分区数发生变化时，之前已经写入的消息可能会被重新分配到不同的分区中。因此，在生产者代码中应该谨慎处理分区数的变化，以避免数据丢失或重复。</p>
<h4 id="副本（Replicas）"><a href="#副本（Replicas）" class="headerlink" title="副本（Replicas）"></a>副本（Replicas）</h4><p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230304130602885.png" alt="image-20230304130602885"></p>
<ul>
<li>副本可以确保某个服务器出现故障时，确保数据依然可用</li>
<li>在Kafka中，一般都会设计副本的个数＞1</li>
</ul>
<h4 id="主题（Topic）"><a href="#主题（Topic）" class="headerlink" title="主题（Topic）"></a>主题（Topic）</h4><p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230304130757615.png" alt="image-20230304130757615"></p>
<ul>
<li>主题是一个逻辑概念，用于生产者发布数据，消费者拉取数据</li>
<li>Kafka中的主题必须要有标识符，而且是唯一的，Kafka中可以有任意数量的主题，没有数量上的限制</li>
<li>在主题中的消息是有结构的，一般一个主题包含某一类消息</li>
<li>一旦生产者发送消息到主题中，这些消息就不能被更新（更改）</li>
</ul>
<h4 id="偏移量（offset）"><a href="#偏移量（offset）" class="headerlink" title="偏移量（offset）"></a>偏移量（offset）</h4><p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230304133000845.png" alt="image-20230304133000845"></p>
<p><strong>offset</strong>记录着下一条将要发送给Consumer的消息的序号</p>
<p><strong>默认Kafka将offset存储在ZooKeeper中</strong></p>
<p>在一个分区中，消息是有顺序的方式存储着，每个在分区的消费都是有一个递增的id。这个就是偏移量offset</p>
<p>偏移量在分区中才是有意义的。在分区之间，offset是没有任何意义的</p>
<h3 id="消费者组"><a href="#消费者组" class="headerlink" title="消费者组"></a>消费者组</h3><p>Kafka支持有多个消费者同时消费一个主题中的数据。我们接下来，给大家演示，启动两个消费者共同来消费 test 主题的数据。</p>
<ol>
<li>首先，修改生产者程序，让生产者不停地每3秒生产1-100个数字。</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 3. 发送1-100数字到Kafka的test主题中</span></span><br><span class="line"><span class="keyword">while</span>(<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>; i &lt;= <span class="number">100</span>; ++i) &#123;</span><br><span class="line">        <span class="comment">// 注意：send方法是一个异步方法，它会将要发送的数据放入到一个buffer中，然后立即返回</span></span><br><span class="line">        <span class="comment">// 这样可以让消息发送变得更高效</span></span><br><span class="line">        producer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;test&quot;</span>, i + <span class="string">&quot;&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">    Thread.sleep(<span class="number">3000</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>接下来，同时运行两个消费者。</li>
</ol>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230304214510037.png" alt="image-20230304214510037"></p>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230304214737410.png" alt="image-20230304214737410"></p>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230304214813494.png" alt="image-20230304214813494"></p>
<ol start="3">
<li>同时运行两个消费者，我们发现，只有一个消费者程序能够拉取到消息。想要让两个消费者同时消费消息，必须要给test主题，添加一个分区。</li>
</ol>
<p># 设置 test topic为2个分区</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --zookeeper <span class="number">10.211</span><span class="number">.55</span><span class="number">.8</span>:<span class="number">2181</span> -alter --partitions <span class="number">2</span> --topic test</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">xuwei@ubuntu1:/export/server/kafka_2.12-2.4.1$ bin/kafka-topics.sh --zookeeper 10.211.55.8:2181 -alter --partitions 2 --topic test</span><br><span class="line">WARNING: If partitions are increased for a topic that has a key, the partition logic or ordering of the messages will be affected</span><br><span class="line">Adding partitions succeeded!</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>重新运行生产者、两个消费者程序，我们就可以看到两个消费者都可以消费Kafka Topic的数据了</li>
</ol>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230304215343589.png" alt="image-20230304215343589"></p>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230304215357086.png" alt="image-20230304215357086"></p>
<h2 id="Kafka生产者幂等性与事务"><a href="#Kafka生产者幂等性与事务" class="headerlink" title="Kafka生产者幂等性与事务"></a>Kafka生产者幂等性与事务</h2><h3 id="幂等性"><a href="#幂等性" class="headerlink" title="幂等性"></a>幂等性</h3><h4 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h4><p>拿http举例来说，一次或多次请求，得到地响应是一致的（网络超时等问题除外），换句话说，就是执行多次操作与执行一次操作的影响是一样的。</p>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230304221941602.png" alt="image-20230304221941602"></p>
<p>如果，某个系统是不具备幂等性的，如果用户重复提交了某个表格，就可能会造成不良影响。例如：用户在浏览器上点击了多次提交订单按钮，会在后台生成多个一模一样的订单。</p>
<h4 id="Kafka生产者幂等性"><a href="#Kafka生产者幂等性" class="headerlink" title="Kafka生产者幂等性"></a>Kafka生产者幂等性</h4><p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230304222141263.png" alt="image-20230304222141263"></p>
<p>在生产者生产消息时，如果出现<code>retry</code>时，有可能会一条消息被发送了多次，如果Kafka不具备幂等性的，就有可能会在<code>partition</code>中保存多条一模一样的消息。</p>
<h4 id="配置幂等性"><a href="#配置幂等性" class="headerlink" title="配置幂等性"></a>配置幂等性</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">props.put(<span class="string">&quot;enable.idempotence&quot;</span>,<span class="literal">true</span>);</span><br></pre></td></tr></table></figure>

<h4 id="幂等性原理"><a href="#幂等性原理" class="headerlink" title="幂等性原理"></a>幂等性原理</h4><p>为了实现生产者的幂等性，Kafka引入了 <code>Producer ID（PID）</code>和 <code>Sequence Number</code>的概念。</p>
<p> <code>PID</code>：每个Producer在初始化时，都会分配一个唯一的PID，这个PID对用户来说，是透明的。</p>
<p> <code>Sequence Number</code>：针对每个生产者（对应PID）发送到指定主题分区的消息都对应一个从0开始递增的<code>Sequence Number</code>。</p>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230304222724389.png" alt="image-20230304222724389"></p>
<h3 id="Kafka事务"><a href="#Kafka事务" class="headerlink" title="Kafka事务"></a>Kafka事务</h3><h4 id="简介-2"><a href="#简介-2" class="headerlink" title="简介"></a>简介</h4><p>Kafka事务是2017年Kafka 0.11.0.0引入的新特性。类似于数据库的事务。Kafka事务指的是生产者生产消息以及消费者提交offset的操作可以在一个原子操作中，要么都成功，要么都失败。尤其是在生产者、消费者并存时，事务的保障尤其重要。（consumer-transform-producer模式）</p>
<p><img src="/Users/xuwei/Desktop/Project/weishao-996.github.io/source/_posts/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/image-20230304222942728.png" alt="image-20230304222942728"></p>
<h4 id="事务操作API"><a href="#事务操作API" class="headerlink" title="事务操作API"></a>事务操作API</h4><p><code>Producer</code>接口中定义了以下5个事务相关方法：</p>
<ol>
<li><p><code>initTransactions</code>（初始化事务）：要使用Kafka事务，必须先进行初始化操作</p>
</li>
<li><p><code>beginTransaction</code>（开始事务）：启动一个Kafka事务</p>
</li>
<li><p><code>sendOffsetsToTransaction</code>（提交偏移量）：批量地将分区对应的offset发送到事务中，方便后续一块提交</p>
</li>
<li><p><code>commitTransaction</code>（提交事务）：提交事务</p>
</li>
<li><p><code>abortTransaction</code>（放弃事务）：取消事务</p>
</li>
</ol>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://weishao-996.github.io">Wei Shao</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://weishao-996.github.io/2023/02/20/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/">https://weishao-996.github.io/2023/02/20/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://weishao-996.github.io" target="_blank">WeiBlog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Kafka/">Kafka</a><a class="post-meta__tags" href="/tags/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98/">黑马程序员</a></div><div class="post_share"><div class="social-share" data-image="/img/bg/WechatIMG48.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/02/23/%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85-ubuntu%E5%AE%89%E8%A3%85kafka/" title="软件安装-ubuntu安装kafka"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">软件安装-ubuntu安装kafka</div></div></a></div><div class="next-post pull-right"><a href="/2023/01/13/%E5%B0%9A%E7%A1%85%E8%B0%B7-Spring-Security/" title="尚硅谷-Spring-Security"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">尚硅谷-Spring-Security</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/11/17/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Docker/" title="黑马程序员-Docker"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-17</div><div class="title">黑马程序员-Docker</div></div></a></div><div><a href="/2022/10/08/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Redis/" title="黑马程序员-Redis"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-08</div><div class="title">黑马程序员-Redis</div></div></a></div><div><a href="/2022/11/21/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-RabbitMQ/" title="黑马程序员-RabbitMQ"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-21</div><div class="title">黑马程序员-RabbitMQ</div></div></a></div><div><a href="/2023/02/23/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Zookeeper/" title="黑马程序员-Zookeeper"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-23</div><div class="title">黑马程序员-Zookeeper</div></div></a></div><div><a href="/2022/11/01/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-%E7%91%9E%E5%90%89%E5%A4%96%E5%8D%96/" title="黑马程序员-瑞吉外卖"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-01</div><div class="title">黑马程序员-瑞吉外卖</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/bg/WechatIMG48.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Wei Shao</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">24</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">16</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/weishao-996"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/weishao-996" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:2427340869@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">写什么代码，一拳把地球打爆！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Kafka%E5%85%A5%E9%97%A8"><span class="toc-number">1.</span> <span class="toc-text">Kafka入门</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-number">1.1.</span> <span class="toc-text">简介</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%AE%80%E4%BB%8B"><span class="toc-number">1.1.1.</span> <span class="toc-text">消息队列简介</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97"><span class="toc-number">1.1.1.1.</span> <span class="toc-text">什么是消息队列</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%AD%E9%97%B4%E4%BB%B6"><span class="toc-number">1.1.1.2.</span> <span class="toc-text">消息队列中间件</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%ABKafka%E5%91%A2"><span class="toc-number">1.1.1.2.1.</span> <span class="toc-text">为什么叫Kafka呢</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">1.1.1.3.</span> <span class="toc-text">消息队列的应用场景</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%BC%82%E6%AD%A5%E5%A4%84%E7%90%86"><span class="toc-number">1.1.1.3.1.</span> <span class="toc-text">异步处理</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%B3%BB%E7%BB%9F%E8%A7%A3%E8%80%A6"><span class="toc-number">1.1.1.3.2.</span> <span class="toc-text">系统解耦</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B5%81%E9%87%8F%E5%89%8A%E5%B3%B0"><span class="toc-number">1.1.1.3.3.</span> <span class="toc-text">流量削峰</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%97%A5%E5%BF%97%E5%A4%84%E7%90%86%EF%BC%88%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%A2%86%E5%9F%9F%E5%B8%B8%E8%A7%81%EF%BC%89"><span class="toc-number">1.1.1.3.4.</span> <span class="toc-text">日志处理（大数据领域常见）</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E3%80%81%E6%B6%88%E8%B4%B9%E8%80%85%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.1.1.4.</span> <span class="toc-text">生产者、消费者模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.1.1.5.</span> <span class="toc-text">消息队列的两种模式</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%82%B9%E5%AF%B9%E7%82%B9%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.1.1.5.1.</span> <span class="toc-text">点对点模式</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.1.1.5.2.</span> <span class="toc-text">发布订阅模式</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E7%AE%80%E4%BB%8B"><span class="toc-number">1.1.2.</span> <span class="toc-text">Kafka简介</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFKafka"><span class="toc-number">1.1.2.1.</span> <span class="toc-text">什么是Kafka</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Kafka%E7%9A%84%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">1.1.2.2.</span> <span class="toc-text">Kafka的应用场景</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Kafka%E8%AF%9E%E7%94%9F%E8%83%8C%E6%99%AF"><span class="toc-number">1.1.2.3.</span> <span class="toc-text">Kafka诞生背景</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E7%9A%84%E4%BC%98%E5%8A%BF"><span class="toc-number">1.1.3.</span> <span class="toc-text">Kafka的优势</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%93%AA%E4%BA%9B%E5%85%AC%E5%8F%B8%E5%9C%A8%E4%BD%BF%E7%94%A8Kafka"><span class="toc-number">1.1.4.</span> <span class="toc-text">哪些公司在使用Kafka</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E7%94%9F%E6%80%81%E5%9C%88%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.1.5.</span> <span class="toc-text">Kafka生态圈介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E7%89%88%E6%9C%AC"><span class="toc-number">1.1.6.</span> <span class="toc-text">Kafka版本</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA"><span class="toc-number">1.2.</span> <span class="toc-text">环境搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%90%AD%E5%BB%BAKafka%E9%9B%86%E7%BE%A4"><span class="toc-number">1.2.1.</span> <span class="toc-text">搭建Kafka集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90"><span class="toc-number">1.2.2.</span> <span class="toc-text">目录结构分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E4%B8%80%E9%94%AE%E5%90%AF%E5%8A%A8-%E5%85%B3%E9%97%AD%E8%84%9A%E6%9C%AC"><span class="toc-number">1.2.3.</span> <span class="toc-text">Kafka一键启动&#x2F;关闭脚本</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C"><span class="toc-number">1.3.</span> <span class="toc-text">基础操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BAtopic"><span class="toc-number">1.3.1.</span> <span class="toc-text">创建topic</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E6%B6%88%E6%81%AF%E5%88%B0Kafka"><span class="toc-number">1.3.2.</span> <span class="toc-text">生产消息到Kafka</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%8EKafka%E6%B6%88%E8%B4%B9%E6%B6%88%E6%81%AF"><span class="toc-number">1.3.3.</span> <span class="toc-text">从Kafka消费消息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8Kafka-Tools%E6%93%8D%E4%BD%9CKafka"><span class="toc-number">1.3.4.</span> <span class="toc-text">使用Kafka Tools操作Kafka</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%9E%E6%8E%A5Kafka%E9%9B%86%E7%BE%A4"><span class="toc-number">1.3.4.1.</span> <span class="toc-text">连接Kafka集群</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BAtopic-1"><span class="toc-number">1.3.4.2.</span> <span class="toc-text">创建topic</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95"><span class="toc-number">1.4.</span> <span class="toc-text">Kafka基准测试</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95"><span class="toc-number">1.4.1.</span> <span class="toc-text">基准测试</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E1%E4%B8%AA%E5%88%86%E5%8C%BA1%E4%B8%AA%E5%89%AF%E6%9C%AC%E7%9A%84%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95"><span class="toc-number">1.4.1.1.</span> <span class="toc-text">基于1个分区1个副本的基准测试</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%9B%E5%BB%BAtopic-2"><span class="toc-number">1.4.1.1.1.</span> <span class="toc-text">创建topic</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E6%B6%88%E6%81%AF%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95"><span class="toc-number">1.4.1.1.2.</span> <span class="toc-text">生产消息基准测试</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E6%B6%88%E6%81%AF%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95"><span class="toc-number">1.4.1.1.3.</span> <span class="toc-text">消费消息基准测试</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E3%E4%B8%AA%E5%88%86%E5%8C%BA1%E4%B8%AA%E5%89%AF%E6%9C%AC%E7%9A%84%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95"><span class="toc-number">1.4.1.2.</span> <span class="toc-text">基于3个分区1个副本的基准测试</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%9B%E5%BB%BAtopic-3"><span class="toc-number">1.4.1.2.1.</span> <span class="toc-text">创建topic</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E6%B6%88%E6%81%AF%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95-1"><span class="toc-number">1.4.1.2.2.</span> <span class="toc-text">生产消息基准测试</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E6%B6%88%E6%81%AF%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95-1"><span class="toc-number">1.4.1.2.3.</span> <span class="toc-text">消费消息基准测试</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E1%E4%B8%AA%E5%88%86%E5%8C%BA3%E4%B8%AA%E5%89%AF%E6%9C%AC%E7%9A%84%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95"><span class="toc-number">1.4.1.3.</span> <span class="toc-text">基于1个分区3个副本的基准测试</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%9B%E5%BB%BAtopic-4"><span class="toc-number">1.4.1.3.1.</span> <span class="toc-text">创建topic</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E6%B6%88%E6%81%AF%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95-2"><span class="toc-number">1.4.1.3.2.</span> <span class="toc-text">生产消息基准测试</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E6%B6%88%E6%81%AF%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95-2"><span class="toc-number">1.4.1.3.3.</span> <span class="toc-text">消费消息基准测试</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Java%E7%BC%96%E7%A8%8B%E6%93%8D%E4%BD%9CKafka"><span class="toc-number">1.5.</span> <span class="toc-text">Java编程操作Kafka</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%8C%E6%AD%A5%E7%94%9F%E4%BA%A7%E6%B6%88%E6%81%AF%E5%88%B0Kafka%E4%B8%AD"><span class="toc-number">1.5.1.</span> <span class="toc-text">同步生产消息到Kafka中</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E6%B1%82"><span class="toc-number">1.5.1.1.</span> <span class="toc-text">需求</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C"><span class="toc-number">1.5.1.2.</span> <span class="toc-text">准备工作</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5Maven-Kafka-POM%E4%BE%9D%E8%B5%96"><span class="toc-number">1.5.1.2.1.</span> <span class="toc-text">导入Maven Kafka POM依赖</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5log4j-properties"><span class="toc-number">1.5.1.2.2.</span> <span class="toc-text">导入log4j.properties</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E5%8C%85%E5%92%8C%E7%B1%BB"><span class="toc-number">1.5.1.2.3.</span> <span class="toc-text">创建包和类</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%BC%80%E5%8F%91"><span class="toc-number">1.5.1.3.</span> <span class="toc-text">代码开发</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%8EKafka%E7%9A%84topic%E4%B8%AD%E6%B6%88%E8%B4%B9%E6%B6%88%E6%81%AF"><span class="toc-number">1.5.2.</span> <span class="toc-text">从Kafka的topic中消费消息</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E6%B1%82-1"><span class="toc-number">1.5.2.1.</span> <span class="toc-text">需求</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C-1"><span class="toc-number">1.5.2.2.</span> <span class="toc-text">准备工作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BC%80%E5%8F%91%E6%AD%A5%E9%AA%A4"><span class="toc-number">1.5.2.3.</span> <span class="toc-text">开发步骤</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E4%BB%A3%E7%A0%81"><span class="toc-number">1.5.2.4.</span> <span class="toc-text">参考代码</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%82%E6%AD%A5%E4%BD%BF%E7%94%A8%E5%B8%A6%E6%9C%89%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%E6%96%B9%E6%B3%95%E7%94%9F%E4%BA%A7%E6%B6%88%E6%81%AF"><span class="toc-number">1.5.3.</span> <span class="toc-text">异步使用带有回调函数方法生产消息</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9E%B6%E6%9E%84"><span class="toc-number">1.6.</span> <span class="toc-text">架构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E9%87%8D%E8%A6%81%E6%A6%82%E5%BF%B5"><span class="toc-number">1.6.1.</span> <span class="toc-text">Kafka重要概念</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#broker"><span class="toc-number">1.6.1.1.</span> <span class="toc-text">broker</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#zookeeper"><span class="toc-number">1.6.1.2.</span> <span class="toc-text">zookeeper</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#producer%EF%BC%88%E7%94%9F%E4%BA%A7%E8%80%85%EF%BC%89"><span class="toc-number">1.6.1.3.</span> <span class="toc-text">producer（生产者）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#consumer%EF%BC%88%E6%B6%88%E8%B4%B9%E8%80%85%EF%BC%89"><span class="toc-number">1.6.1.4.</span> <span class="toc-text">consumer（消费者）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#consumer-group%EF%BC%88%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%EF%BC%89"><span class="toc-number">1.6.1.5.</span> <span class="toc-text">consumer group（消费者组）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%EF%BC%88Partitions%EF%BC%89"><span class="toc-number">1.6.1.6.</span> <span class="toc-text">分区（Partitions）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%89%AF%E6%9C%AC%EF%BC%88Replicas%EF%BC%89"><span class="toc-number">1.6.1.7.</span> <span class="toc-text">副本（Replicas）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E9%A2%98%EF%BC%88Topic%EF%BC%89"><span class="toc-number">1.6.1.8.</span> <span class="toc-text">主题（Topic）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%81%8F%E7%A7%BB%E9%87%8F%EF%BC%88offset%EF%BC%89"><span class="toc-number">1.6.1.9.</span> <span class="toc-text">偏移量（offset）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84"><span class="toc-number">1.6.2.</span> <span class="toc-text">消费者组</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka%E7%94%9F%E4%BA%A7%E8%80%85%E5%B9%82%E7%AD%89%E6%80%A7%E4%B8%8E%E4%BA%8B%E5%8A%A1"><span class="toc-number">1.7.</span> <span class="toc-text">Kafka生产者幂等性与事务</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B9%82%E7%AD%89%E6%80%A7"><span class="toc-number">1.7.1.</span> <span class="toc-text">幂等性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B-1"><span class="toc-number">1.7.1.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Kafka%E7%94%9F%E4%BA%A7%E8%80%85%E5%B9%82%E7%AD%89%E6%80%A7"><span class="toc-number">1.7.1.2.</span> <span class="toc-text">Kafka生产者幂等性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E5%B9%82%E7%AD%89%E6%80%A7"><span class="toc-number">1.7.1.3.</span> <span class="toc-text">配置幂等性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B9%82%E7%AD%89%E6%80%A7%E5%8E%9F%E7%90%86"><span class="toc-number">1.7.1.4.</span> <span class="toc-text">幂等性原理</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E4%BA%8B%E5%8A%A1"><span class="toc-number">1.7.2.</span> <span class="toc-text">Kafka事务</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B-2"><span class="toc-number">1.7.2.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8B%E5%8A%A1%E6%93%8D%E4%BD%9CAPI"><span class="toc-number">1.7.2.2.</span> <span class="toc-text">事务操作API</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/02/23/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Zookeeper/" title="黑马程序员-Zookeeper">黑马程序员-Zookeeper</a><time datetime="2023-02-23T08:15:22.000Z" title="发表于 2023-02-23 16:15:22">2023-02-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/02/23/%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85-ubuntu%E5%AE%89%E8%A3%85kafka/" title="软件安装-ubuntu安装kafka">软件安装-ubuntu安装kafka</a><time datetime="2023-02-23T08:04:43.000Z" title="发表于 2023-02-23 16:04:43">2023-02-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/02/20/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-Kafka/" title="黑马程序员-Kafka">黑马程序员-Kafka</a><time datetime="2023-02-20T12:40:50.000Z" title="发表于 2023-02-20 20:40:50">2023-02-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/01/13/%E5%B0%9A%E7%A1%85%E8%B0%B7-Spring-Security/" title="尚硅谷-Spring-Security">尚硅谷-Spring-Security</a><time datetime="2023-01-13T09:39:30.000Z" title="发表于 2023-01-13 17:39:30">2023-01-13</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/11/21/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98-RabbitMQ/" title="黑马程序员-RabbitMQ">黑马程序员-RabbitMQ</a><time datetime="2022-11-21T02:52:22.000Z" title="发表于 2022-11-21 10:52:22">2022-11-21</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/img/bg/iTab-7p3we9.jpeg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Wei Shao</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>